{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib import rcParams\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      X1            id FINAL_LABEL  \\\n",
      "0      1  1.251010e+18  IRRELEVANT   \n",
      "1      2  1.250140e+18    RELEVANT   \n",
      "2      3  1.250960e+18  IRRELEVANT   \n",
      "4      5  1.248700e+18  IRRELEVANT   \n",
      "5      6  1.248840e+18  IRRELEVANT   \n",
      "6      7  1.249810e+18  IRRELEVANT   \n",
      "7      8  1.248690e+18  IRRELEVANT   \n",
      "8      9  1.249800e+18  IRRELEVANT   \n",
      "9     10  1.248690e+18  IRRELEVANT   \n",
      "10    11  1.249780e+18  IRRELEVANT   \n",
      "11    13  1.250590e+18  IRRELEVANT   \n",
      "12    14  1.249760e+18  IRRELEVANT   \n",
      "13    16  1.250150e+18  IRRELEVANT   \n",
      "14    17  1.250610e+18  IRRELEVANT   \n",
      "15    18  1.249210e+18  IRRELEVANT   \n",
      "16    20  1.249550e+18  IRRELEVANT   \n",
      "17    21  1.250590e+18  IRRELEVANT   \n",
      "18    23  1.250960e+18  IRRELEVANT   \n",
      "19    24  1.250800e+18  IRRELEVANT   \n",
      "20    25  1.250800e+18  IRRELEVANT   \n",
      "22    27  1.249360e+18  IRRELEVANT   \n",
      "23    28  1.250150e+18  IRRELEVANT   \n",
      "24    29  1.249520e+18  IRRELEVANT   \n",
      "25    30  1.249190e+18  IRRELEVANT   \n",
      "26    32  1.250810e+18  IRRELEVANT   \n",
      "27    33  1.249350e+18  IRRELEVANT   \n",
      "28    34  1.250560e+18  IRRELEVANT   \n",
      "29    35  1.250550e+18  IRRELEVANT   \n",
      "30    36  1.249570e+18    RELEVANT   \n",
      "31    37  1.248670e+18  IRRELEVANT   \n",
      "..   ...           ...         ...   \n",
      "480  366  1.248850e+18  IRRELEVANT   \n",
      "481  367  1.250960e+18  IRRELEVANT   \n",
      "482  370  1.248670e+18  IRRELEVANT   \n",
      "483  372  1.249760e+18  IRRELEVANT   \n",
      "484  378  1.250790e+18  IRRELEVANT   \n",
      "485  384  1.249530e+18  IRRELEVANT   \n",
      "486  386  1.249810e+18  IRRELEVANT   \n",
      "487  399  1.249150e+18  IRRELEVANT   \n",
      "488  409  1.249540e+18  IRRELEVANT   \n",
      "489  411  1.250810e+18  IRRELEVANT   \n",
      "491  417  1.248810e+18    RELEVANT   \n",
      "492  441  1.250820e+18    RELEVANT   \n",
      "493  442  1.250960e+18  IRRELEVANT   \n",
      "494  443  1.250590e+18  IRRELEVANT   \n",
      "495  448  1.250740e+18    RELEVANT   \n",
      "496  454  1.249350e+18  IRRELEVANT   \n",
      "497  459  1.249340e+18  IRRELEVANT   \n",
      "498  460  1.250930e+18  IRRELEVANT   \n",
      "499  461  1.249120e+18    RELEVANT   \n",
      "500  466  1.249750e+18  IRRELEVANT   \n",
      "501  471  1.250760e+18  IRRELEVANT   \n",
      "502  474  1.250830e+18  IRRELEVANT   \n",
      "503  477  1.249160e+18  IRRELEVANT   \n",
      "504  491  1.248830e+18  IRRELEVANT   \n",
      "505  498  1.250980e+18  IRRELEVANT   \n",
      "506  500  1.250810e+18  IRRELEVANT   \n",
      "507  502  1.249130e+18  IRRELEVANT   \n",
      "508  506  1.249770e+18  IRRELEVANT   \n",
      "509  508  1.248800e+18  IRRELEVANT   \n",
      "510  510  1.250830e+18  IRRELEVANT   \n",
      "\n",
      "                                                  text  LABEL  \n",
      "0    i saw someone under that tweet say “nO tAxeS n...    0.0  \n",
      "1    🧟‍♂️ \\nScientists Confirm First Case of COVID-...    1.0  \n",
      "2    “The new requirements are bound to make face c...    0.0  \n",
      "4    🚨ATTENTION #SmallBizDC Community🚨\\nJoin DSLBD ...    0.0  \n",
      "5                   🥺 and I want my face in some pussy    0.0  \n",
      "6    🤣🤣🤣🤣 over two million people did and they are ...    0.0  \n",
      "7    🚨🚨🔊 Today @GovernorVA signs ✍️in-state tuition...    0.0  \n",
      "8    🚨🚨College Coaches🚨🚨\\n\\nBringing your spring ev...    0.0  \n",
      "9    🙏❤️Please donate to Feed the Front Lines, as @...    0.0  \n",
      "10   🙏 For Easter Sunday, Father Planning and three...    0.0  \n",
      "11   😷 Tati just gon sit in her damn vomit...and st...    0.0  \n",
      "12   😭😭😭 Nbs I Look At 3 Stories And Be Irritated.....    0.0  \n",
      "13   😢😢😢😢😢 May God give you peace n ability to abso...    0.0  \n",
      "14   😎😎😎😎😎\\n#panda #pandaexpress @ College Park, Ma...    0.0  \n",
      "15   😅 we get so much shit just for existing... htt...    0.0  \n",
      "16   😂😂😂 they funny af talking about Lebron was on ...    0.0  \n",
      "17   😂😂😂 crying at the “weird people” at the end. h...    0.0  \n",
      "18   🗓On This Date🗓Jerry Dewayne Plaster disappeare...    0.0  \n",
      "19   🔥 Big news!\\n\\nYou can access Washington Consu...    0.0  \n",
      "20   📢 During the daily conference of President @lo...    0.0  \n",
      "22   🐰⚽️🌷🌻🥚 Happy Easter we wish you and your famil...    0.0  \n",
      "23   🎶 Empty lake, empty streets, the sun goes down...    0.0  \n",
      "24   🎵 Supermarket, oh, what packet of crackers to ...    0.0  \n",
      "25                   🍽Eating Food my Mother brung me 😩    0.0  \n",
      "26   🍓👩‍🍳LIVING | BY | EXAMPLE👩‍🍳🍓🥣 \\nI’ve been an ...    0.0  \n",
      "27   🌸Mi~🙈SNeaK P👀K~\\nL👁👁K what the Easter Bunny 🐇🥕...    0.0  \n",
      "28   🌸Mi~🔥⚡️SALE $225\\n60”wide, 20”deep, 36”tall\\nT...    0.0  \n",
      "29   🌸Mi~💐Whos thinking Mother’s Day?~❤️EVERY mothe...    0.0  \n",
      "30   🇺🇸USA Numbers🚨\\n \\nInfections 560,300 (+27,421...    1.0  \n",
      "31   ⬜️⬜️GIVEAWAY⬜️⬜️\\n🔴🟠🟡🟢🔵🟣\\nWinner gets my Blue ...    0.0  \n",
      "..                                                 ...    ...  \n",
      "480  Hey we're with you Dan &amp; Laura!, scary ain...    0.0  \n",
      "481  Hey guys, this was bought to my attention at W...    0.0  \n",
      "482  Hello everyone, collectively as we journey the...    0.0  \n",
      "483  Hazard pay to all grocery workers! \\n\\nCompani...    0.0  \n",
      "484  Funny time today 4/16/20; 8:00 pm/ET, as some ...    0.0  \n",
      "485  Florida. 😑\\nFlorida inmates will start making ...    0.0  \n",
      "486  Every day I go on a social distancing walk in ...    0.0  \n",
      "487  Covid-19 economic turmoil\\n\\nGive freely to th...    0.0  \n",
      "488            COVID-19 IS A FUCKIN STUPID ASS BITCH 🙄    0.0  \n",
      "489  By all means @IngrahamAngle ..  you and your f...    0.0  \n",
      "491  Because when over 2,000 people die in one day ...    1.0  \n",
      "492  @sethgs @DrOz I don’t know where he’s from but...    1.0  \n",
      "493  @sab9293 I think we will find out the death co...    0.0  \n",
      "494  @realDonaldTrump 😡🤬 You idiot, now isn’t the t...    0.0  \n",
      "495  @realDonaldTrump More than 30,000 Americans ar...    1.0  \n",
      "496  @pj_nola @prim_siripipat @realDonaldTrump No, ...    0.0  \n",
      "497  @kylegriffin1 This is horrible! Where was trum...    0.0  \n",
      "498                                             #NAME?    0.0  \n",
      "499  @judywbrandt I agree with you. It isn’t coming...    1.0  \n",
      "500  @heyitsabree It is not done. We still aren't t...    0.0  \n",
      "501  @domenicadelia22 @Humbert18960727 Somehow the ...    0.0  \n",
      "502                                             #NAME?    0.0  \n",
      "503  @atulbutte @Apple @mistercharlie @cultofmac Th...    0.0  \n",
      "504  @RyanAFournier Ryan, I met Surgeon General Ada...    0.0  \n",
      "505  @PressSec @realDonaldTrump ONE PERCENT?  1% of...    0.0  \n",
      "506  @PonyFortyTwo Right, that’s why I posted this ...    0.0  \n",
      "507  @OANN You need to be treated Just like Fox ( s...    0.0  \n",
      "508  @MayorBowser @_DCHealth @DC_HSEMA People are f...    0.0  \n",
      "509  @MattWalshBlog @emilycrockett So the fact the ...    0.0  \n",
      "510  yall don’t understand how much my blood is boi...    0.0  \n",
      "\n",
      "[469 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('C:/Users/qw508/OneDrive/Documents/Covid-19 Twitter/client_labels_train.csv')\n",
    "df_test = pd.read_csv('C:/Users/qw508/OneDrive/Documents/Covid-19 Twitter/client_labels_test.csv')\n",
    "#combine train and test data into review_df\n",
    "review_df = df_train.append(df_test, ignore_index=True)\n",
    "#remove NA\n",
    "review_df = review_df.dropna()\n",
    "#convert irrelevant to 0 and relevant to 1\n",
    "df_train.loc[(df_train['FINAL_LABEL'] == 'IRRELEVANT'), 'LABEL'] = 0\n",
    "df_train.loc[(df_train['FINAL_LABEL'] != 'IRRELEVANT'), 'LABEL'] = 1  \n",
    "df_test.loc[(df_test['FINAL_LABEL'] == 'IRRELEVANT'), 'LABEL'] = 0\n",
    "df_test.loc[(df_test['FINAL_LABEL'] != 'IRRELEVANT'), 'LABEL'] = 1  \n",
    "review_df.loc[(review_df['FINAL_LABEL'] == 'IRRELEVANT'), 'LABEL'] = 0\n",
    "review_df.loc[(review_df['FINAL_LABEL'] != 'IRRELEVANT'), 'LABEL'] = 1  \n",
    "print (review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRRELEVANT    391\n",
       "RELEVANT       78\n",
       "Name: FINAL_LABEL, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['FINAL_LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRRELEVANT    0.833689\n",
       "RELEVANT      0.166311\n",
       "Name: FINAL_LABEL, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating baseline accuracy\n",
    "review_df['FINAL_LABEL'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tokenizer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the contents of selftext to lowercase\n",
    "review_df.loc[:,'text'] = review_df.text.apply(lambda x : str.lower(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing hyper link, latin characters and digits\n",
    "review_df['text']=review_df['text'].str.replace('http.*.*', '',regex = True)\n",
    "review_df['text']=review_df['text'].str.replace('û.*.*', '',regex = True)\n",
    "review_df['text']=review_df['text'].str.replace(r'\\d+','',regex= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['tokens'] = review_df['text'].map(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>id</th>\n",
       "      <th>FINAL_LABEL</th>\n",
       "      <th>text</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.251010e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>i saw someone under that tweet say “no taxes n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[saw, someone, tweet, say, taxes, check, sir, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.250140e+18</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>🧟‍♂️ \\nscientists confirm first case of covid-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[scientists, confirm, first, case, covid, tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.250960e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>“the new requirements are bound to make face c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[new, requirements, bound, make, face, coverin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.248700e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>🚨attention #smallbizdc community🚨\\njoin dslbd ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[attention, smallbizdc, community, join, dslbd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.248840e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>🥺 and i want my face in some pussy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[want, face, pussy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1            id FINAL_LABEL  \\\n",
       "0   1  1.251010e+18  IRRELEVANT   \n",
       "1   2  1.250140e+18    RELEVANT   \n",
       "2   3  1.250960e+18  IRRELEVANT   \n",
       "4   5  1.248700e+18  IRRELEVANT   \n",
       "5   6  1.248840e+18  IRRELEVANT   \n",
       "\n",
       "                                                text  LABEL  \\\n",
       "0  i saw someone under that tweet say “no taxes n...    0.0   \n",
       "1  🧟‍♂️ \\nscientists confirm first case of covid-...    1.0   \n",
       "2  “the new requirements are bound to make face c...    0.0   \n",
       "4  🚨attention #smallbizdc community🚨\\njoin dslbd ...    0.0   \n",
       "5                 🥺 and i want my face in some pussy    0.0   \n",
       "\n",
       "                                              tokens  \n",
       "0  [saw, someone, tweet, say, taxes, check, sir, ...  \n",
       "1  [scientists, confirm, first, case, covid, tran...  \n",
       "2  [new, requirements, bound, make, face, coverin...  \n",
       "4  [attention, smallbizdc, community, join, dslbd...  \n",
       "5                                [want, face, pussy]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Printing English stopwords\n",
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning stopwords to a variable\n",
    "stop = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding this stop word to list of stopwords as it appears on frequently occuring word\n",
    "item=['amp'] #'https','co','http','û','ûò','ûó','û_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop.extend(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords from tokens\n",
    "review_df['tokens']=review_df['tokens'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing lemmatizer \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Instantiating lemmatizer \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>id</th>\n",
       "      <th>FINAL_LABEL</th>\n",
       "      <th>text</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.251010e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>i saw someone under that tweet say “no taxes n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[saw, someone, tweet, say, taxes, check, sir, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.250140e+18</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>🧟‍♂️ \\nscientists confirm first case of covid-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[scientists, confirm, first, case, covid, tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.250960e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>“the new requirements are bound to make face c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[new, requirements, bound, make, face, coverin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.248700e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>🚨attention #smallbizdc community🚨\\njoin dslbd ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[attention, smallbizdc, community, join, dslbd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.248840e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>🥺 and i want my face in some pussy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[want, face, pussy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1            id FINAL_LABEL  \\\n",
       "0   1  1.251010e+18  IRRELEVANT   \n",
       "1   2  1.250140e+18    RELEVANT   \n",
       "2   3  1.250960e+18  IRRELEVANT   \n",
       "3   5  1.248700e+18  IRRELEVANT   \n",
       "4   6  1.248840e+18  IRRELEVANT   \n",
       "\n",
       "                                                text  LABEL  \\\n",
       "0  i saw someone under that tweet say “no taxes n...    0.0   \n",
       "1  🧟‍♂️ \\nscientists confirm first case of covid-...    1.0   \n",
       "2  “the new requirements are bound to make face c...    0.0   \n",
       "3  🚨attention #smallbizdc community🚨\\njoin dslbd ...    0.0   \n",
       "4                 🥺 and i want my face in some pussy    0.0   \n",
       "\n",
       "                                              tokens  \n",
       "0  [saw, someone, tweet, say, taxes, check, sir, ...  \n",
       "1  [scientists, confirm, first, case, covid, tran...  \n",
       "2  [new, requirements, bound, make, face, coverin...  \n",
       "3  [attention, smallbizdc, community, join, dslbd...  \n",
       "4                                [want, face, pussy]  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = review_df.reset_index(drop=True)\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>id</th>\n",
       "      <th>FINAL_LABEL</th>\n",
       "      <th>text</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.251010e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>i saw someone under that tweet say “no taxes n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[saw, someone, tweet, say, taxes, check, sir, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.250140e+18</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>🧟‍♂️ \\nscientists confirm first case of covid-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[scientists, confirm, first, case, covid, tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.250960e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>“the new requirements are bound to make face c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[new, requirements, bound, make, face, coverin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.248700e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>🚨attention #smallbizdc community🚨\\njoin dslbd ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[attention, smallbizdc, community, join, dslbd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.248840e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>🥺 and i want my face in some pussy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[want, face, pussy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1            id FINAL_LABEL  \\\n",
       "0   1  1.251010e+18  IRRELEVANT   \n",
       "1   2  1.250140e+18    RELEVANT   \n",
       "2   3  1.250960e+18  IRRELEVANT   \n",
       "4   5  1.248700e+18  IRRELEVANT   \n",
       "5   6  1.248840e+18  IRRELEVANT   \n",
       "\n",
       "                                                text  LABEL  \\\n",
       "0  i saw someone under that tweet say “no taxes n...    0.0   \n",
       "1  🧟‍♂️ \\nscientists confirm first case of covid-...    1.0   \n",
       "2  “the new requirements are bound to make face c...    0.0   \n",
       "4  🚨attention #smallbizdc community🚨\\njoin dslbd ...    0.0   \n",
       "5                 🥺 and i want my face in some pussy    0.0   \n",
       "\n",
       "                                              tokens  \n",
       "0  [saw, someone, tweet, say, taxes, check, sir, ...  \n",
       "1  [scientists, confirm, first, case, covid, tran...  \n",
       "2  [new, requirements, bound, make, face, coverin...  \n",
       "4  [attention, smallbizdc, community, join, dslbd...  \n",
       "5                                [want, face, pussy]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize_words=[]\n",
    "for i in range (len(review_df['tokens'])):\n",
    "    word=''\n",
    "    for j in range(len(review_df['tokens'][i])):\n",
    "        lemm_word=lemmatizer.lemmatize(review_df['tokens'][i][j])#lemmatize\n",
    "        \n",
    "        word=word + ' ' + lemm_word # joining tokens into sentence    \n",
    "    lemmatize_words.append(word) # store in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column to store the result\n",
    "review_df['lemmatized']=lemmatize_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>id</th>\n",
       "      <th>FINAL_LABEL</th>\n",
       "      <th>text</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.251010e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>i saw someone under that tweet say “no taxes n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[saw, someone, tweet, say, taxes, check, sir, ...</td>\n",
       "      <td>saw someone tweet say tax check sir pls choke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.250140e+18</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>🧟‍♂️ \\nscientists confirm first case of covid-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[scientists, confirm, first, case, covid, tran...</td>\n",
       "      <td>scientist confirm first case covid transmitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.250960e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>“the new requirements are bound to make face c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[new, requirements, bound, make, face, coverin...</td>\n",
       "      <td>new requirement bound make face covering ines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.248700e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>🚨attention #smallbizdc community🚨\\njoin dslbd ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[attention, smallbizdc, community, join, dslbd...</td>\n",
       "      <td>attention smallbizdc community join dslbd sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.248840e+18</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>🥺 and i want my face in some pussy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[want, face, pussy]</td>\n",
       "      <td>want face pussy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1            id FINAL_LABEL  \\\n",
       "0   1  1.251010e+18  IRRELEVANT   \n",
       "1   2  1.250140e+18    RELEVANT   \n",
       "2   3  1.250960e+18  IRRELEVANT   \n",
       "3   5  1.248700e+18  IRRELEVANT   \n",
       "4   6  1.248840e+18  IRRELEVANT   \n",
       "\n",
       "                                                text  LABEL  \\\n",
       "0  i saw someone under that tweet say “no taxes n...    0.0   \n",
       "1  🧟‍♂️ \\nscientists confirm first case of covid-...    1.0   \n",
       "2  “the new requirements are bound to make face c...    0.0   \n",
       "3  🚨attention #smallbizdc community🚨\\njoin dslbd ...    0.0   \n",
       "4                 🥺 and i want my face in some pussy    0.0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [saw, someone, tweet, say, taxes, check, sir, ...   \n",
       "1  [scientists, confirm, first, case, covid, tran...   \n",
       "2  [new, requirements, bound, make, face, coverin...   \n",
       "3  [attention, smallbizdc, community, join, dslbd...   \n",
       "4                                [want, face, pussy]   \n",
       "\n",
       "                                          lemmatized  \n",
       "0   saw someone tweet say tax check sir pls choke...  \n",
       "1   scientist confirm first case covid transmitte...  \n",
       "2   new requirement bound make face covering ines...  \n",
       "3   attention smallbizdc community join dslbd sma...  \n",
       "4                                    want face pussy  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing logistics Regression Model \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = review_df['lemmatized']\n",
    "y = review_df['FINAL_LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418     roger stone bill gate may created coronavirus...\n",
       "203     perversely greater lockdown succeeds stopping...\n",
       "351     capitalweather positive note made social dist...\n",
       "303      black make covid death dc mayor guess good mine\n",
       "391     complacent covering severity crisis beginning...\n",
       "Name: lemmatized, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418    IRRELEVANT\n",
       "203    IRRELEVANT\n",
       "351    IRRELEVANT\n",
       "303    IRRELEVANT\n",
       "391    IRRELEVANT\n",
       "Name: FINAL_LABEL, dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRRELEVANT    293\n",
       "RELEVANT       58\n",
       "Name: FINAL_LABEL, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ensuring that the value counts are quite evenly distributed\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),  \n",
    "    ('lr', LogisticRegression()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qw508\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8319088319088319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 2500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_params = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__min_df': [2,3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=tuned_params, cv=3) # Evaluating model on unseen data\n",
    "\n",
    "model_lr=gs.fit(X_train, y_train) # Fitting model\n",
    "\n",
    "# This is the average of all cv folds for a single \n",
    "#combination of the parameters specified in the tuned_params\n",
    "print(gs.best_score_) \n",
    "\n",
    "#displaying the best values of parameters\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9515669515669516"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135593220338984"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions!\n",
    "predictions_lr = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the confusion matrix function\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95,  3],\n",
       "       [19,  1]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating confusion matrix\n",
    "confusion_matrix(y_test, predictions_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpreting confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_lr).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 95\n",
      "False Positives: 3\n",
      "False Negatives: 19\n",
      "True Positives: 1\n"
     ]
    }
   ],
   "source": [
    "#values with coreesponding labels\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_logi = 1/(1+19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_logi = (1+95)/(95+3+19+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135593220338984"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_logi\n",
    "accuracy_logi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model- Navie Bayes Model\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating CountVectorizer.\n",
    "cvec = CountVectorizer(max_features = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform() fits the model and transforms training data into feature vectors\n",
    "X_train_cvec = cvec.fit_transform(X_train, y_train).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranform test data and convert into array\n",
    "X_test_cvec = cvec.transform(X_test).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model\n",
    "model_nb=nb.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions\n",
    "predictions_nb = model_nb.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629629629629629"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training score\n",
    "model_nb.score(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8050847457627118"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "model_nb.score(X_test_cvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92,  6],\n",
       "       [17,  3]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating confusion matrix\n",
    "confusion_matrix(y_test, predictions_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpreting confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_nb).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 92\n",
      "False Positives: 6\n",
      "False Negatives: 17\n",
      "True Positives: 3\n"
     ]
    }
   ],
   "source": [
    "#values with coreesponding labels\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_bayes = 3/(3+17)\n",
    "accuracy_bayes = (3+92)/(92+6+17+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8050847457627118"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_bayes\n",
    "accuracy_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "accuracy 0.8305084745762712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "accuracy 0.788135593220339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qw508\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "%time\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_march = pd.read_csv('C:/Users/qw508/OneDrive/Documents/Covid-19 Twitter/march_tweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1608, 6)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_march.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1244771412939702273</td>\n",
       "      <td>,uiiyk9, aPalo Alto church reports that a pers...</td>\n",
       "      <td>2020-03-30 23:40:06+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1244767238961291264</td>\n",
       "      <td>I been breathing the Shoreview sewage air my w...</td>\n",
       "      <td>2020-03-30 23:23:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1244766646700363777</td>\n",
       "      <td>@fredreker the next 2 months are gonna get sha...</td>\n",
       "      <td>2020-03-30 23:21:09+00:00</td>\n",
       "      <td>@fredreker</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1244763563559759873</td>\n",
       "      <td>Please, please stay at home. respect to those ...</td>\n",
       "      <td>2020-03-30 23:08:54+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1244763456911200257</td>\n",
       "      <td>COVID-19 = OVER</td>\n",
       "      <td>2020-03-30 23:08:29+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   id  \\\n",
       "0           0  1244771412939702273   \n",
       "1           1  1244767238961291264   \n",
       "2           2  1244766646700363777   \n",
       "3           3  1244763563559759873   \n",
       "4           4  1244763456911200257   \n",
       "\n",
       "                                                Text  \\\n",
       "0  ,uiiyk9, aPalo Alto church reports that a pers...   \n",
       "1  I been breathing the Shoreview sewage air my w...   \n",
       "2  @fredreker the next 2 months are gonna get sha...   \n",
       "3  Please, please stay at home. respect to those ...   \n",
       "4                                   COVID-19 = OVER    \n",
       "\n",
       "                        Date    Mentions Hashtags  \n",
       "0  2020-03-30 23:40:06+00:00         NaN      NaN  \n",
       "1  2020-03-30 23:23:31+00:00         NaN      NaN  \n",
       "2  2020-03-30 23:21:09+00:00  @fredreker      NaN  \n",
       "3  2020-03-30 23:08:54+00:00         NaN      NaN  \n",
       "4  2020-03-30 23:08:29+00:00         NaN      NaN  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_march.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove NA\n",
    "df_march = df_march.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the contents of selftext to lowercase\n",
    "df_march.loc[:,'Text'] = df_march.Text.apply(lambda x : str.lower(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing hyper link, latin characters and digits\n",
    "df_march['Text']=df_march['Text'].str.replace('http.*.*', '',regex = True)\n",
    "df_march['Text']=df_march['Text'].str.replace('û.*.*', '',regex = True)\n",
    "df_march['Text']=df_march['Text'].str.replace(r'\\d+','',regex= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_march['tokens'] = df_march['Text'].map(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords from tokens\n",
    "df_march['tokens']=df_march['tokens'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1244724436781031424</td>\n",
       "      <td>with the #boyking @realdonaldtrump as presiden...</td>\n",
       "      <td>2020-03-30 20:33:26+00:00</td>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td>#BoyKing #COVID</td>\n",
       "      <td>[boyking, realdonaldtrump, president, response...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1244718490197487616</td>\n",
       "      <td>thank you @gavinnewsom - for your thoughtful, ...</td>\n",
       "      <td>2020-03-30 20:09:48+00:00</td>\n",
       "      <td>@GavinNewsom</td>\n",
       "      <td>#FlattenTheCurve</td>\n",
       "      <td>[thank, gavinnewsom, thoughtful, practical, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>1244699841243930630</td>\n",
       "      <td>worst perpetrators and schemers. cong n ak in ...</td>\n",
       "      <td>2020-03-30 18:55:42+00:00</td>\n",
       "      <td>@BloombergQuint</td>\n",
       "      <td>#ChineseVirus19</td>\n",
       "      <td>[worst, perpetrators, schemers, cong, n, ak, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>1244663669750808578</td>\n",
       "      <td>thank you @startuphealth for having me on your...</td>\n",
       "      <td>2020-03-30 16:31:58+00:00</td>\n",
       "      <td>@startuphealth</td>\n",
       "      <td>#COVID19 #Covid_19 #healthcare</td>\n",
       "      <td>[thank, startuphealth, covid, innovations, pod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>1244469668275879936</td>\n",
       "      <td>my little contribution to the pm cares covid- ...</td>\n",
       "      <td>2020-03-30 03:41:04+00:00</td>\n",
       "      <td>@PMOIndia @narendramodi</td>\n",
       "      <td>#PMcaresfund #pmcares</td>\n",
       "      <td>[little, contribution, pm, cares, covid, relie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   id  \\\n",
       "0          22  1244724436781031424   \n",
       "1          23  1244718490197487616   \n",
       "2          29  1244699841243930630   \n",
       "3          36  1244663669750808578   \n",
       "4          59  1244469668275879936   \n",
       "\n",
       "                                                Text  \\\n",
       "0  with the #boyking @realdonaldtrump as presiden...   \n",
       "1  thank you @gavinnewsom - for your thoughtful, ...   \n",
       "2  worst perpetrators and schemers. cong n ak in ...   \n",
       "3  thank you @startuphealth for having me on your...   \n",
       "4  my little contribution to the pm cares covid- ...   \n",
       "\n",
       "                        Date                 Mentions  \\\n",
       "0  2020-03-30 20:33:26+00:00         @realDonaldTrump   \n",
       "1  2020-03-30 20:09:48+00:00             @GavinNewsom   \n",
       "2  2020-03-30 18:55:42+00:00          @BloombergQuint   \n",
       "3  2020-03-30 16:31:58+00:00           @startuphealth   \n",
       "4  2020-03-30 03:41:04+00:00  @PMOIndia @narendramodi   \n",
       "\n",
       "                         Hashtags  \\\n",
       "0                 #BoyKing #COVID   \n",
       "1                #FlattenTheCurve   \n",
       "2                 #ChineseVirus19   \n",
       "3  #COVID19 #Covid_19 #healthcare   \n",
       "4           #PMcaresfund #pmcares   \n",
       "\n",
       "                                              tokens  \n",
       "0  [boyking, realdonaldtrump, president, response...  \n",
       "1  [thank, gavinnewsom, thoughtful, practical, de...  \n",
       "2  [worst, perpetrators, schemers, cong, n, ak, c...  \n",
       "3  [thank, startuphealth, covid, innovations, pod...  \n",
       "4  [little, contribution, pm, cares, covid, relie...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_march = df_march.reset_index(drop=True)\n",
    "df_march.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize_words=[]\n",
    "for i in range (len(df_march['tokens'])):\n",
    "    word=''\n",
    "    for j in range(len(df_march['tokens'][i])):\n",
    "        lemm_word=lemmatizer.lemmatize(df_march['tokens'][i][j])#lemmatize\n",
    "        \n",
    "        word=word + ' ' + lemm_word # joining tokens into sentence    \n",
    "    lemmatize_words.append(word) # store in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column to store the result\n",
    "df_march['lemmatized']=lemmatize_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1244724436781031424</td>\n",
       "      <td>with the #boyking @realdonaldtrump as presiden...</td>\n",
       "      <td>2020-03-30 20:33:26+00:00</td>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td>#BoyKing #COVID</td>\n",
       "      <td>[boyking, realdonaldtrump, president, response...</td>\n",
       "      <td>boyking realdonaldtrump president response co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1244718490197487616</td>\n",
       "      <td>thank you @gavinnewsom - for your thoughtful, ...</td>\n",
       "      <td>2020-03-30 20:09:48+00:00</td>\n",
       "      <td>@GavinNewsom</td>\n",
       "      <td>#FlattenTheCurve</td>\n",
       "      <td>[thank, gavinnewsom, thoughtful, practical, de...</td>\n",
       "      <td>thank gavinnewsom thoughtful practical decisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>1244699841243930630</td>\n",
       "      <td>worst perpetrators and schemers. cong n ak in ...</td>\n",
       "      <td>2020-03-30 18:55:42+00:00</td>\n",
       "      <td>@BloombergQuint</td>\n",
       "      <td>#ChineseVirus19</td>\n",
       "      <td>[worst, perpetrators, schemers, cong, n, ak, c...</td>\n",
       "      <td>worst perpetrator schemer cong n ak cahoot sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>1244663669750808578</td>\n",
       "      <td>thank you @startuphealth for having me on your...</td>\n",
       "      <td>2020-03-30 16:31:58+00:00</td>\n",
       "      <td>@startuphealth</td>\n",
       "      <td>#COVID19 #Covid_19 #healthcare</td>\n",
       "      <td>[thank, startuphealth, covid, innovations, pod...</td>\n",
       "      <td>thank startuphealth covid innovation podcast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>1244469668275879936</td>\n",
       "      <td>my little contribution to the pm cares covid- ...</td>\n",
       "      <td>2020-03-30 03:41:04+00:00</td>\n",
       "      <td>@PMOIndia @narendramodi</td>\n",
       "      <td>#PMcaresfund #pmcares</td>\n",
       "      <td>[little, contribution, pm, cares, covid, relie...</td>\n",
       "      <td>little contribution pm care covid relief fund...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   id  \\\n",
       "0          22  1244724436781031424   \n",
       "1          23  1244718490197487616   \n",
       "2          29  1244699841243930630   \n",
       "3          36  1244663669750808578   \n",
       "4          59  1244469668275879936   \n",
       "\n",
       "                                                Text  \\\n",
       "0  with the #boyking @realdonaldtrump as presiden...   \n",
       "1  thank you @gavinnewsom - for your thoughtful, ...   \n",
       "2  worst perpetrators and schemers. cong n ak in ...   \n",
       "3  thank you @startuphealth for having me on your...   \n",
       "4  my little contribution to the pm cares covid- ...   \n",
       "\n",
       "                        Date                 Mentions  \\\n",
       "0  2020-03-30 20:33:26+00:00         @realDonaldTrump   \n",
       "1  2020-03-30 20:09:48+00:00             @GavinNewsom   \n",
       "2  2020-03-30 18:55:42+00:00          @BloombergQuint   \n",
       "3  2020-03-30 16:31:58+00:00           @startuphealth   \n",
       "4  2020-03-30 03:41:04+00:00  @PMOIndia @narendramodi   \n",
       "\n",
       "                         Hashtags  \\\n",
       "0                 #BoyKing #COVID   \n",
       "1                #FlattenTheCurve   \n",
       "2                 #ChineseVirus19   \n",
       "3  #COVID19 #Covid_19 #healthcare   \n",
       "4           #PMcaresfund #pmcares   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [boyking, realdonaldtrump, president, response...   \n",
       "1  [thank, gavinnewsom, thoughtful, practical, de...   \n",
       "2  [worst, perpetrators, schemers, cong, n, ak, c...   \n",
       "3  [thank, startuphealth, covid, innovations, pod...   \n",
       "4  [little, contribution, pm, cares, covid, relie...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0   boyking realdonaldtrump president response co...  \n",
       "1   thank gavinnewsom thoughtful practical decisi...  \n",
       "2   worst perpetrator schemer cong n ak cahoot sp...  \n",
       "3   thank startuphealth covid innovation podcast ...  \n",
       "4   little contribution pm care covid relief fund...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_march.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistics Regression Model\n",
    "X = df_march['lemmatized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions from logistics Regression Model\n",
    "predictions_march_lr = model_lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_march['Prediction'] = predictions_march_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    8\n",
       "id            8\n",
       "Text          8\n",
       "Date          8\n",
       "Mentions      8\n",
       "Hashtags      8\n",
       "tokens        8\n",
       "lemmatized    8\n",
       "Prediction    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_march.loc[df_march.Prediction == 'RELEVANT'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 9)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_march.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.263157894736842"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# about 5% relevant tweets\n",
    "8/152 * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bays Model\n",
    "X_test_cvec = df_march.lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranform march data and convert into array\n",
    "X_test_cvec = cvec.transform(X_test_cvec).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions from Naive Bays model \n",
    "predictions_march_nb = model_nb.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_march['Prediction'] = predictions_march_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1244724436781031424</td>\n",
       "      <td>with the #boyking @realdonaldtrump as presiden...</td>\n",
       "      <td>2020-03-30 20:33:26+00:00</td>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td>#BoyKing #COVID</td>\n",
       "      <td>[boyking, realdonaldtrump, president, response...</td>\n",
       "      <td>boyking realdonaldtrump president response co...</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1244718490197487616</td>\n",
       "      <td>thank you @gavinnewsom - for your thoughtful, ...</td>\n",
       "      <td>2020-03-30 20:09:48+00:00</td>\n",
       "      <td>@GavinNewsom</td>\n",
       "      <td>#FlattenTheCurve</td>\n",
       "      <td>[thank, gavinnewsom, thoughtful, practical, de...</td>\n",
       "      <td>thank gavinnewsom thoughtful practical decisi...</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>1244699841243930630</td>\n",
       "      <td>worst perpetrators and schemers. cong n ak in ...</td>\n",
       "      <td>2020-03-30 18:55:42+00:00</td>\n",
       "      <td>@BloombergQuint</td>\n",
       "      <td>#ChineseVirus19</td>\n",
       "      <td>[worst, perpetrators, schemers, cong, n, ak, c...</td>\n",
       "      <td>worst perpetrator schemer cong n ak cahoot sp...</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>1244663669750808578</td>\n",
       "      <td>thank you @startuphealth for having me on your...</td>\n",
       "      <td>2020-03-30 16:31:58+00:00</td>\n",
       "      <td>@startuphealth</td>\n",
       "      <td>#COVID19 #Covid_19 #healthcare</td>\n",
       "      <td>[thank, startuphealth, covid, innovations, pod...</td>\n",
       "      <td>thank startuphealth covid innovation podcast ...</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>1244469668275879936</td>\n",
       "      <td>my little contribution to the pm cares covid- ...</td>\n",
       "      <td>2020-03-30 03:41:04+00:00</td>\n",
       "      <td>@PMOIndia @narendramodi</td>\n",
       "      <td>#PMcaresfund #pmcares</td>\n",
       "      <td>[little, contribution, pm, cares, covid, relie...</td>\n",
       "      <td>little contribution pm care covid relief fund...</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   id  \\\n",
       "0          22  1244724436781031424   \n",
       "1          23  1244718490197487616   \n",
       "2          29  1244699841243930630   \n",
       "3          36  1244663669750808578   \n",
       "4          59  1244469668275879936   \n",
       "\n",
       "                                                Text  \\\n",
       "0  with the #boyking @realdonaldtrump as presiden...   \n",
       "1  thank you @gavinnewsom - for your thoughtful, ...   \n",
       "2  worst perpetrators and schemers. cong n ak in ...   \n",
       "3  thank you @startuphealth for having me on your...   \n",
       "4  my little contribution to the pm cares covid- ...   \n",
       "\n",
       "                        Date                 Mentions  \\\n",
       "0  2020-03-30 20:33:26+00:00         @realDonaldTrump   \n",
       "1  2020-03-30 20:09:48+00:00             @GavinNewsom   \n",
       "2  2020-03-30 18:55:42+00:00          @BloombergQuint   \n",
       "3  2020-03-30 16:31:58+00:00           @startuphealth   \n",
       "4  2020-03-30 03:41:04+00:00  @PMOIndia @narendramodi   \n",
       "\n",
       "                         Hashtags  \\\n",
       "0                 #BoyKing #COVID   \n",
       "1                #FlattenTheCurve   \n",
       "2                 #ChineseVirus19   \n",
       "3  #COVID19 #Covid_19 #healthcare   \n",
       "4           #PMcaresfund #pmcares   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [boyking, realdonaldtrump, president, response...   \n",
       "1  [thank, gavinnewsom, thoughtful, practical, de...   \n",
       "2  [worst, perpetrators, schemers, cong, n, ak, c...   \n",
       "3  [thank, startuphealth, covid, innovations, pod...   \n",
       "4  [little, contribution, pm, cares, covid, relie...   \n",
       "\n",
       "                                          lemmatized  Prediction  \n",
       "0   boyking realdonaldtrump president response co...  IRRELEVANT  \n",
       "1   thank gavinnewsom thoughtful practical decisi...  IRRELEVANT  \n",
       "2   worst perpetrator schemer cong n ak cahoot sp...  IRRELEVANT  \n",
       "3   thank startuphealth covid innovation podcast ...  IRRELEVANT  \n",
       "4   little contribution pm care covid relief fund...  IRRELEVANT  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_march.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    15\n",
       "id            15\n",
       "Text          15\n",
       "Date          15\n",
       "Mentions      15\n",
       "Hashtags      15\n",
       "tokens        15\n",
       "lemmatized    15\n",
       "Prediction    15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_march.loc[df_march.Prediction == 'RELEVANT'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 9)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_march.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09868421052631579"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#About 9% of Relevant tweets\n",
    "15/152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_march.to_csv('C:/Users/qw508/OneDrive/Documents/march_tweet_labeled.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
